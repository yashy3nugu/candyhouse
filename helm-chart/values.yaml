# Global configuration
global:
  environment: production
  kafka:
    url: candyhouse-kafka:9092
  logging:
    format: "combined"
    directory: "logs"

# Store UI Configuration
storeUI:
  name: store-ui
  image:
    repository: yashyenugu/candyhouse-frontend
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 250m
      memory: 256Mi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 60
  replicas: 1
  
# User Service Configuration
userService:
  name: user-service
  image:
    repository: yashyenugu/user-service
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 7000
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 60
  replicas: 1
  
# Order Service Configuration
orderService:
  name: order-service
  image:
    repository: yashyenugu/order-service
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 5000
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 60
  replicas: 1
  
# Product Service Configuration
productService:
  name: product-service
  image:
    repository: yashyenugu/product-service
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 4000
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 60
  replicas: 1

# Secrets configuration
secrets:
  # Secret names in Kubernetes
  kafka:
    create: true
    name: kafka-secret
  userService:
    create: true
    name: user-service-secrets
  orderService:
    create: true
    name: order-service-secrets
  productService:
    create: true
    name: product-service-secrets
  cloudinary:
    create: true
    name: cloudinary-secrets
  jwt:
    create: true
    name: jwt-secret
    expiresIn: "24"

# Kafka Configuration
kafka:
  enabled: true
  name: candyhouse-kafka
  image:
    repository: confluentinc/cp-kafka
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 9092
  env:
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: candyhouse-zookeeper:2181
    KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://candyhouse-kafka:9092
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi
  topics:
    - name: user
      partitions: 3
      replicationFactor: 1
    - name: candy
      partitions: 3
      replicationFactor: 1
    - name: quantity
      partitions: 3
      replicationFactor: 1
    - name: test
      partitions: 3
      replicationFactor: 1

# Zookeeper Configuration
zookeeper:
  enabled: true
  name: candyhouse-zookeeper
  image:
    repository: confluentinc/cp-zookeeper
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 2181
  env:
    ZOOKEEPER_CLIENT_PORT: 2181
    ZOOKEEPER_TICK_TIME: 2000
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 250m
      memory: 512Mi

# Kafka UI Configuration
kafkaUI:
  enabled: true
  name: candyhouse-kafka-ui
  image:
    repository: provectuslabs/kafka-ui
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8080
  env:
    KAFKA_CLUSTERS_0_NAME: candyhouse-kafka
    KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: candyhouse-kafka:9092
    KAFKA_CLUSTERS_0_ZOOKEEPER: candyhouse-zookeeper:2181
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 250m
      memory: 256Mi

# Ingress configuration
ingress:
  enabled: true
  host: "candyhouse.com"
  paths:
    userService: "/user-service(/|$)(.*)$"
    orderService: "/order-service(/|$)(.*)$"
    productService: "/product-service(/|$)(.*)$"
    storeUI: "/store-ui(/|$)(.*)$"

# Ingress Controller configuration
ingressController:
  enabled: true
  replicaCount: 1
  image:
    repository: k8s.gcr.io/ingress-nginx/controller
    tag: "v1.8.0"
    pullPolicy: IfNotPresent
  service:
    type: LoadBalancer
    port: 80 
  
# Logging Configuration
# elasticsearch:
#   enabled: true
#   replicas: 1
#   minimumMasterNodes: 1
#   master:
#     resources:
#       requests:
#         cpu: "500m"
#         memory: "1Gi"
#       limits:
#         cpu: "2000m"
#         memory: "2Gi"
#     persistence:
#       enabled: true
#       size: 10Gi
#       storageClass: "standard-rwo"
#     securityContext:
#       runAsUser: 1000
#       runAsGroup: 1000
#       fsGroup: 1000
#     extraEnvs:
#       - name: bootstrap.memory_lock
#         value: "false"
#       - name: ES_JAVA_OPTS
#         value: "-Xms512m -Xmx512m"
#       - name: discovery.type
#         value: "single-node"
#       - name: cluster.initial_master_nodes
#         value: ""
#   data:
#     resources:
#       requests:
#         cpu: "500m"
#         memory: "1Gi"
#       limits:
#         cpu: "2000m"
#         memory: "2Gi"
#     persistence:
#       enabled: true
#       size: 10Gi
#       storageClass: "standard-rwo"
#     securityContext:
#       runAsUser: 1000
#       runAsGroup: 1000
#       fsGroup: 1000
#     extraEnvs:
#       - name: bootstrap.memory_lock
#         value: "false"
#       - name: ES_JAVA_OPTS
#         value: "-Xms512m -Xmx512m"
#       - name: discovery.type
#         value: "single-node"
#       - name: cluster.initial_master_nodes
#         value: ""
#   coordinator:
#     resources:
#       requests:
#         cpu: "500m"
#         memory: "1Gi"
#       limits:
#         cpu: "2000m"
#         memory: "2Gi"
#     persistence:
#       enabled: true
#       size: 10Gi
#       storageClass: "standard-rwo"
#     securityContext:
#       runAsUser: 1000
#       runAsGroup: 1000
#       fsGroup: 1000
#     extraEnvs:
#       - name: bootstrap.memory_lock
#         value: "false"
#       - name: ES_JAVA_OPTS
#         value: "-Xms512m -Xmx512m"
#       - name: discovery.type
#         value: "single-node"
#       - name: cluster.initial_master_nodes
#         value: ""

# kibana:
#   enabled: true
#   service:
#     type: LoadBalancer

# logstash:
#   enabled: true
#   logstashConfig:
#     logstash.yml: |
#       http.host: "0.0.0.0"
#   service:
#     annotations: {}
#     type: ClusterIP
#     loadBalancerIP: ""
#     ports:
#       - name: beats
#         port: 5044
#         protocol: TCP
#         targetPort: 5044
#       - name: http
#         port: 8080
#         protocol: TCP
#         targetPort: 8080
#   pipelines:
#     redirect-nodes:
#       config: |
#         input {
#           beats { port => 5044 }
#         }
#         # filter {
#         #   if [fields][service] in ["order-service", "product-service", "user-service", "store-ui"] {
#         #     mutate { add_field => { "index" => "%{[fields][service]}-logs" } }
#         #   }
#         # }
#         output {
#           elasticsearch {
#             hosts => ["http://elasticsearch-master:9200"]
#             user => ${ELASTICSEARCH_USERNAME}
#             password => ${ELASTICSEARCH_PASSWORD}
#             # cacert => '/usr/share/logstash/config/certs/ca.crt'
#             # index => "test"
#           }
#           stdout { codec => rubydebug }
#         }
      
#       extraEnvs:
#       - name: "ELASTICSEARCH_USERNAME"
#         valueFrom:
#           secretKeyRef:
#             name: elasticsearch-master-credentials
#             key: username
#       - name: "ELASTICSEARCH_PASSWORD"
#         valueFrom:
#           secretKeyRef:
#             name: elasticsearch-master-credentials
#             key: password
#   secretMounts:
#     - name: elasticsearch-master-certs
#       secretName: elasticsearch-master-certs
#       path: /usr/share/logstash/config/certs

# # Added logging configuration for subchart
# debug:
#   enabled: false

# # Filebeat configuration to collect container logs and forward them to Logstash
# filebeat:
#   enabled: true
#   extraVolumes:
#     - name: varlogpods
#       hostPath:
#         path: /var/log/pods
#         type: DirectoryOrCreate
#   extraVolumeMounts:
#     - name: varlogpods
#       mountPath: /var/log/pods
#       readOnly: true
#   filebeatConfig:
#     filebeat.yml: |
#       filebeat.inputs:
#       - type: container
#         paths:
#           - /var/log/pods/*/*/*.log
#         processors:
#         # - add_kubernetes_metadata:
#         #     host: ${NODE_NAME}
#         #     in_cluster: true
#         #     matchers:
#         #       - logs_path:
#         #           logs_path:
#         #             - "/var/log/pods/"
#       output.logstash:
#         hosts: ["candyhouse-logstash-headless:5044"]

# Redis configuration for Bitnami Redis with Sentinel and Replication
redis:
  # in memory only
  configMap: |
    save ""
    appendonly no
  architecture: replication  # Set to 'replication' for master-slave replication
  master:
    persistence:
      enabled: false        # Disable PVC creation for master
  replica:
    replicaCount: 2         # Number of replicas to create for Redis
    persistence:
      enabled: false        # Disable PVC creation for replica
  sentinel:
    enabled: true           # Enable Redis Sentinel for high availability and automatic failover
    masterSet: mymaster     # The name of the Redis master set
    replicas: 2             # Number of replica nodes
    quorum: 2               # Minimum number of Sentinels that need to agree for failover
    sentinels:
      - "10.0.0.1"        # Example Sentinel 1
      - "10.0.0.2"        # Example Sentinel 2
  auth:
    enabled: true           # Enable Redis authentication
    password: "your-redis-password"  # Set the password for Redis instance
  resources:
    limits:
      cpu: "1"
      memory: "64Mi"      # Set memory limit to 64MB for each Redis instance
    requests:
      cpu: "500m"
      memory: "64Mi"      # Set memory request to 64MB for each Redis instance

